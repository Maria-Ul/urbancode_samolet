{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/albivaltzew/urbancode_samolet/blob/main/augment_coco_ipynb%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_Y0pxwc0WZM",
        "outputId": "f24dd924-9347-46c2-d8b8-1973f9bd4f8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install opencv-python-headless numpy pycocotools\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Pgx6jPD61gj",
        "outputId": "ef5794d2-859c-4d4e-d523-cafde898ae55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (2.0.7)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade albumentations\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvHRsmMU8xGh",
        "outputId": "848ee841-91b9-4ec5-8d60-0142d087112c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.11.2)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.19.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations) (6.0.1)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.8.0.76)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations) (1.2.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations) (4.5.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (3.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (2.31.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (2023.8.30)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (23.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pycocotools.coco import COCO\n",
        "\n",
        "\n",
        "\n",
        "COCO_ANNO_PATH = '/content/drive/MyDrive/urbancode/urbanhack-train/annotations/instances_default.json'\n",
        "COCO_IMG_PATH  = '/content/drive/MyDrive/urbancode/urbanhack-train/images'\n",
        "\n",
        "coco = COCO(COCO_ANNO_PATH)"
      ],
      "metadata": {
        "id": "9cf5T5m3qumR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0a9bfd1-3de1-442b-d334-171d2f8f0e96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.98s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import albumentations as A\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "UvGuzwsv9WlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_augmented_images = 1"
      ],
      "metadata": {
        "id": "uKAzzIAO97Gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_labels = [\"window\", \"empty\", \"filled\"]\n"
      ],
      "metadata": {
        "id": "YeKxzbui-JUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *save* in coco format"
      ],
      "metadata": {
        "id": "rPDiAXy0-jjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply augmentation techniques to images and store them\n",
        "augmented_images = []\n",
        "updated_annotations = []\n",
        "# Perform augmentation and update annotations\n",
        "l = 0\n",
        "for image_id in (coco.imgs.keys()):\n",
        "    l+=1\n",
        "    print(l)\n",
        "    image_info = coco.imgs[image_id]\n",
        "    annotations = coco.loadAnns(coco.getAnnIds([image_id]))\n",
        "    image = cv2.imread(f'{COCO_IMG_PATH}/{image_info[\"file_name\"]}')\n",
        "    print(f'{COCO_IMG_PATH}/{image_info[\"file_name\"]}')\n",
        "\n",
        "    # Apply augmentation techniques (e.g., rotation, flipping, scaling)\n",
        "    bboxes = []\n",
        "    class_categories = []\n",
        "    for i in range(len(annotations)):\n",
        "          bboxes.append(annotations[i][\"bbox\"])\n",
        "          class_categories.append(annotations[i]['category_id'])\n",
        "\n",
        "\n",
        "    transform = A.Compose([\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.Rotate(limit=30, p=0.2),\n",
        "        A.OneOf([\n",
        "            A.RandomBrightnessContrast(p=0.5),\n",
        "            A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2, p=0.5), # изменение цвета\n",
        "            A.augmentations.transforms.GaussNoise(var_limit=(10,50),mean=0,p=0.5), # шум гаусса\n",
        "            A.augmentations.transforms.CLAHE (clip_limit=4.0, tile_grid_size=(8, 8), always_apply=False, p=0.5)\n",
        "        ], p=0.3),\n",
        "        A.Blur(blur_limit=3, p=0.1), # Размытие\n",
        "        # A.augmentations.transforms.Equalize(),\n",
        "        A.augmentations.geometric.transforms.Affine(p=0.1, shear={'x': (-30, 30), 'y': (-30, 30)}),\n",
        "        A.OneOf([\n",
        "            A.augmentations.transforms.ToGray(p=0.2), # оттенки серого\n",
        "            A.RandomRain(brightness_coefficient=0.9, drop_width=1, blur_value=3, p=0.2), # добавляет дождь\n",
        "            A.RandomSnow(brightness_coeff=2.5, snow_point_lower=0.3, snow_point_upper=0.5, p=0.2), #Добавляет снег\n",
        "            A.RandomFog(fog_coef_lower=0.3, fog_coef_upper=0.6, alpha_coef=0.1, p=0.2), # туман\n",
        "            A.RandomSunFlare(flare_roi=(0, 0, 1, 0.5), angle_lower=0.5, p=0.22), # солнечные блики\n",
        "        ],p=0.3),\n",
        "    ], bbox_params=A.BboxParams(format='coco', min_area=1024, min_visibility=0.3, label_fields=['class_categories']))\n",
        "\n",
        "    for _ in range(num_augmented_images):\n",
        "        augmented = transform(image=image, bboxes=bboxes,  class_categories=class_categories)\n",
        "        augmented_image = augmented['image']\n",
        "        augmented_bboxes = augmented['bboxes']\n",
        "        augmented_categories = augmented['class_categories']\n",
        "        augmented_images.append(augmented_image)\n",
        "\n",
        "\n",
        "        # Create a new annotation entry for the augmented image\n",
        "        updated_annotation = []\n",
        "        for i in range(len(augmented_bboxes)):\n",
        "\n",
        "          updated_ann = {\n",
        "              'image_id': annotations[i]['image_id'],\n",
        "              'category_id': augmented_categories[i],\n",
        "              'id':i+1,  # Make sure to keep the original ID\n",
        "              'bbox': augmented_bboxes[i],\n",
        "              'area': augmented_bboxes[i][2]*augmented_bboxes[i][3],  # You may need to adjust this depending on the augmentation\n",
        "              'segmentation': annotations[i]['segmentation'],  # You may need to adjust this depending on the augmentation\n",
        "              'iscrowd': annotations[i]['iscrowd'],  # You may need to adjust this depending on the augmentation\n",
        "          }\n",
        "\n",
        "          # Append updated annotation to the list\n",
        "          updated_annotation.append(updated_ann)\n",
        "    updated_annotations.append(updated_annotation)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pQJ3Bikh8O7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "ZjWF8l-CAOR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create updated annotations dictionary\n",
        "updated_annotations_data = {\n",
        "    'images': coco.dataset['images'],\n",
        "    'annotations': updated_annotations,\n",
        "    'categories': coco.dataset['categories']\n",
        "}\n",
        "\n",
        "# Save the updated annotations in COCO format\n",
        "with open('/content/drive/MyDrive/urbancode/urbanhack-train/updated_annotations.json', 'w') as f:\n",
        "    json.dump(updated_annotations_data, f)\n"
      ],
      "metadata": {
        "id": "CIRV0a0Q-2Pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_images_directory = \"/content/drive/MyDrive/urbancode/urbanhack-train/augmented_images_new\"\n",
        "os.mkdir(augmented_images_directory)\n",
        "for i, augmented_image in enumerate(augmented_images):\n",
        "    cv2.imwrite(os.path.join(augmented_images_directory, f\"augmented_image_{i}.jpg\"), augmented_image)\n"
      ],
      "metadata": {
        "id": "PJObD-KY8Spy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *save* in yolo"
      ],
      "metadata": {
        "id": "niidneMW-agY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the function to convert COCO annotations to YOLO format\n",
        "def coco_to_yolo(bbox, category_id, image_width, image_height):\n",
        "    x_center = (bbox[0] + bbox[2]) / 2\n",
        "    y_center = (bbox[1] + bbox[3]) / 2\n",
        "    width = bbox[2]\n",
        "    height = bbox[3]\n",
        "\n",
        "    # Normalize coordinates\n",
        "    x_center /= image_width\n",
        "    y_center /= image_height\n",
        "    width /= image_width\n",
        "    height /= image_height\n",
        "\n",
        "    return f\"{category_id} {x_center} {y_center} {width} {height}\"\n",
        "\n"
      ],
      "metadata": {
        "id": "ymAHD8VG_gDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a directory to store YOLO annotations\n",
        "augmented_labels_directory  = \"/content/drive/MyDrive/urbancode/urbanhack-train/augmented_data_yolo/labels\"\n",
        "os.makedirs(augmented_labels_directory , exist_ok=True)\n",
        "augmented_images_directory = \"/content/drive/MyDrive/urbancode/urbanhack-train/augmented_data_yolo/images\"\n",
        "os.mkdir(augmented_images_directory)"
      ],
      "metadata": {
        "id": "t6dCZXFjBARZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply augmentation techniques to images and store them\n",
        "augmented_images = []\n",
        "# Perform augmentation and update annotations\n",
        "for (l, image_id) in enumerate(coco.imgs.keys()):\n",
        "    image_info = coco.imgs[image_id]\n",
        "    annotations = coco.loadAnns(coco.getAnnIds([image_id]))\n",
        "    image = cv2.imread(f'{COCO_IMG_PATH}/{image_info[\"file_name\"]}')\n",
        "\n",
        "    # Apply augmentation techniques (e.g., rotation, flipping, scaling)\n",
        "    bboxes = []\n",
        "    class_categories = []\n",
        "    for i in range(len(annotations)):\n",
        "          bboxes.append(annotations[i][\"bbox\"])\n",
        "          class_categories.append(annotations[i]['category_id'])\n",
        "\n",
        "\n",
        "    transform = A.Compose([\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.Rotate(limit=30, p=0.2),\n",
        "        A.OneOf([\n",
        "            A.RandomBrightnessContrast(p=0.5),\n",
        "            A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2, p=0.5), # изменение цвета\n",
        "            A.augmentations.transforms.GaussNoise(var_limit=(10,50),mean=0,p=0.5), # шум гаусса\n",
        "            A.augmentations.transforms.CLAHE (clip_limit=4.0, tile_grid_size=(8, 8), always_apply=False, p=0.5)\n",
        "        ], p=0.3),\n",
        "        A.Blur(blur_limit=3, p=0.1), # Размытие\n",
        "        # A.augmentations.transforms.Equalize(),\n",
        "        A.augmentations.geometric.transforms.Affine(p=0.1, shear={'x': (-30, 30), 'y': (-30, 30)}),\n",
        "        A.OneOf([\n",
        "            A.augmentations.transforms.ToGray(p=0.2), # оттенки серого\n",
        "            A.RandomRain(brightness_coefficient=0.9, drop_width=1, blur_value=3, p=0.2), # добавляет дождь\n",
        "            A.RandomSnow(brightness_coeff=2.5, snow_point_lower=0.3, snow_point_upper=0.5, p=0.2), #Добавляет снег\n",
        "            A.RandomFog(fog_coef_lower=0.3, fog_coef_upper=0.6, alpha_coef=0.1, p=0.2), # туман\n",
        "            A.RandomSunFlare(flare_roi=(0, 0, 1, 0.5), angle_lower=0.5, p=0.22), # солнечные блики\n",
        "        ],p=0.3),\n",
        "    ], bbox_params=A.BboxParams(format='coco', min_area=1024, min_visibility=0.3, label_fields=['class_categories']))\n",
        "\n",
        "    for j in range(num_augmented_images):\n",
        "        augmented = transform(image=image, bboxes=bboxes,  class_categories=class_categories)\n",
        "        augmented_image = augmented['image']\n",
        "        augmented_bboxes = augmented['bboxes']\n",
        "        augmented_categories = augmented['class_categories']\n",
        "        augmented_images.append(augmented_image)\n",
        "\n",
        "        # Iterate over annotations and save YOLO format annotations\n",
        "        for i in range(len(augmented_bboxes)):\n",
        "\n",
        "            image_width = augmented_image.shape[0]\n",
        "            image_height = augmented_image.shape[1]\n",
        "            bbox = augmented_bboxes[i]\n",
        "            category_id = augmented_categories[i]\n",
        "            yolo_annotation = coco_to_yolo(bbox, category_id, image_width, image_height)\n",
        "\n",
        "\n",
        "            # Create an annotation file for each image\n",
        "            num_im = l+j\n",
        "            annotation_file_name = os.path.join(augmented_labels_directory, (f\"augmented_image_{num_im}\" + \".txt\"))\n",
        "            # Write YOLO annotation to file\n",
        "            with open(annotation_file_name, 'a') as f:\n",
        "                f.write(yolo_annotation + '\\n')\n",
        "\n",
        "            cv2.imwrite(os.path.join(augmented_images_directory, f\"augmented_image_{num_im}.jpg\"), augmented_image)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "amC_vN0KEDdq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "5d52cee5-0532-4c9e-bff9-d755fc836e3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-47562fb1ef85>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myolo_annotation\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maugmented_images_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"augmented_image_{num_im}.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugmented_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2j0r0M01_G-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "sND6esyc_P-b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}